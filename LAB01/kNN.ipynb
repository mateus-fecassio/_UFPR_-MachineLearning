{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import preprocessing\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data, K_value, distance, vet_acur, vet_confusion):\n",
    "\n",
    "        # loads data\n",
    "        #print (\"Loading data...\")\n",
    "        X_data, y_data = load_svmlight_file(data)\n",
    "        # splits data\n",
    "        #print (\"Spliting data...\")\n",
    "        X_train, X_test, y_train, y_test =  train_test_split(X_data, y_data, test_size=0.5, random_state = 5)\n",
    "        # x vetor de características e Y labels\n",
    "        X_train = X_train.toarray()\n",
    "        X_test = X_test.toarray()\n",
    "\n",
    "        # fazer a normalizacao dos dados #######\n",
    "        #scaler = preprocessing.MinMaxScaler()\n",
    "        #X_train = scaler.fit_transform(X_train_dense)\n",
    "        #X_test = scaler.fit_transform(X_test_dense)\n",
    "        \n",
    "        # cria um kNN\n",
    "        neigh = KNeighborsClassifier(n_neighbors=K_value, metric=distance)\n",
    "        #treinamento\n",
    "        #print ('Fitting knn')\n",
    "        neigh.fit(X_train, y_train)\n",
    "\n",
    "        # predicao do classificador\n",
    "        #print ('Predicting...')\n",
    "        y_pred = neigh.predict(X_test)\n",
    "\n",
    "        # mostra o resultado do classificador na base de teste\n",
    "        print ('Accuracy: ',  neigh.score(X_test, y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #salva no vetor de acurácias\n",
    "        vet_acur.append(neigh.score(X_test, y_test))\n",
    "        \n",
    "        \n",
    "\n",
    "        # cria a matriz de confusao\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        #salva no vetor de confusoes\n",
    "        vet_confusion.append(cm)\n",
    "        \n",
    "        \n",
    "#         print (cm)\n",
    "#         print(classification_report(y_test, y_pred, labels=[0,1,2,3,4,5,6,7,8,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archive = 'features_1.txt'\n",
    "\n",
    "# main(archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vet_k = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean = []\n",
    "euclidean_confusion = []\n",
    "\n",
    "manhattan = []\n",
    "manhattan_confusion = []\n",
    "\n",
    "minkowski = []\n",
    "minkowski_confusion = []\n",
    "\n",
    "chebyshev = []\n",
    "chebyshev_confusion = []\n",
    "\n",
    "vet_acur = []\n",
    "vet_confusion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = ['euclidean', 'manhattan', 'minkowski', 'chebyshev']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PARA PEGAR O VALOR DA ACURÁCIA PARA DIFERENTES TAMANHOS QUE GERAM O VETOR DE CARACTERÍSTICAS [X,Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = ['features_4.txt','features_2.txt','features_1.txt','features_3.txt','features_7.txt','features_6.txt','features_5.txt','features_10.txt','features_9.txt','features_8.txt']\n",
    "\n",
    "for archive in arquivos:\n",
    "    main(archive, 3, 'euclidean', vet_acur, vet_confusion)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PARA PEGAR O VALOR DA ACURÁCIA PARA DIFERENTES VALORES DE K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = 'features_6.txt'\n",
    "\n",
    "for distance in method:\n",
    "    vet_acur = []\n",
    "    vet_confusion = []\n",
    "    for k_value in range(1,11,1):\n",
    "        print(distance,': k =',k_value)\n",
    "        main(archive, k_value, distance, vet_acur, vet_confusion)\n",
    "    \n",
    "    if distance == 'euclidean':\n",
    "        euclidean = vet_acur.copy()\n",
    "        euclidean_confusion = vet_confusion.copy()\n",
    "    elif distance == 'manhattan':\n",
    "        manhattan = vet_acur.copy()\n",
    "        manhattan_confusion = vet_confusion.copy()\n",
    "    elif distance == 'minkowski':\n",
    "        minkowski = vet_acur.copy()\n",
    "        minkowski_confusion = vet_confusion.copy()\n",
    "    else:\n",
    "        chebyshev = vet_acur.copy()\n",
    "        chebyshev_confusion = vet_confusion.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ([ax1, ax2], [ax3, ax4]) = plt.subplots(2,2,figsize=(25,15), sharex=True)\n",
    "#fig.suptitle('Comparativo da acurácia entre o uso de diferentes métricas de distâncias para diferentes tamanhos de redimensionamento das imagens ')\n",
    "\n",
    "ax1.plot(vet_k, euclidean,'.-')\n",
    "# ax1.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "ax1.set_ylabel('Acurácia Euclidiana')\n",
    "ax1.grid()\n",
    "\n",
    "\n",
    "ax2.plot(vet_k, manhattan, '.-')\n",
    "# ax2.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "ax2.set_ylabel('Acurácia Manhattan')\n",
    "ax2.grid()\n",
    "\n",
    "\n",
    "ax3.plot(vet_k, minkowski, '.-')\n",
    "# ax3.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "ax3.set_ylabel('Acurácia Minkowski')\n",
    "ax3.set_xlabel('K')\n",
    "ax3.grid()\n",
    "\n",
    "\n",
    "ax4.plot(vet_k, chebyshev, '.-')\n",
    "# ax4.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "ax4.set_ylabel('Acurácia Chebyshev')\n",
    "ax4.set_xlabel('K')\n",
    "ax4.grid()\n",
    "\n",
    "\n",
    "plt.xticks(vet_k)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('k_variation.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/43374920/how-to-automatically-annotate-maximum-value-in-pyplot\n",
    "#https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "def annot_max(x,y, ax=None):\n",
    "    xmax = x[np.argmax(y)]\n",
    "    ymax = y.max()\n",
    "    text= \"x={:.3f}, y={:.3f}\".format(xmax, ymax)\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"angle,angleA=0,angleB=60\")\n",
    "    kw = dict(xycoords='data',textcoords=\"axes fraction\",\n",
    "              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"top\")\n",
    "    ax.annotate(text, xy=(xmax, ymax), xytext=(0.94,0.96), **kw)\n",
    "\n",
    "ax.plot(vet_k, chebyshev)\n",
    "\n",
    "\n",
    "tempx = np.array(vet_k)\n",
    "tempy = np.array(chebyshev)\n",
    "annot_max(tempx,tempy)\n",
    "\n",
    "ax.set(xlabel='K', ylabel='acurácia')\n",
    "# ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "ax.grid()\n",
    "\n",
    "plt.xticks(vet_k)\n",
    "\n",
    "fig.savefig(\"chebyshev.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----MATRIZ DE CONFUSÃO (DISTÂNCIA EUCLIDIANA) -----')\n",
    "print('- K=1\\n', euclidean_confusion[0])\n",
    "print('\\n\\n')\n",
    "print('- K=10\\n', euclidean_confusion[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----MATRIZ DE CONFUSÃO (DISTÂNCIA DE MANHATTAN) -----')\n",
    "print('- K=1\\n', manhattan_confusion[0])\n",
    "print('\\n\\n')\n",
    "print('- K=10\\n', manhattan_confusion[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----MATRIZ DE CONFUSÃO (DISTÂNCIA DE MINKOWSKI) -----')\n",
    "print('- K=1\\n', minkowski_confusion[0])\n",
    "print('\\n\\n')\n",
    "print('- K=10\\n', minkowski_confusion[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----MATRIZ DE CONFUSÃO (DISTÂNCIA DE CHEBYSHEV) -----')\n",
    "print('- K=5\\n', chebyshev_confusion[4])\n",
    "print('\\n\\n')\n",
    "print('- K=7\\n', chebyshev_confusion[6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}